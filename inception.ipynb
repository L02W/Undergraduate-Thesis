{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import tensorflow as tf\n",
    "\n",
    "using_gpu = tf.test.is_gpu_available()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TRAIN_SIZE = 8005\n",
    "TEST_SIZE = 2023\n",
    "\n",
    "TRAIN_DIR = '/Users/luoluo/BLS/DataBase/jpg/train_set'\n",
    "TEST_DIR = '/Users/luoluo/BLS/DataBase/jpg/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Found 7828 images belonging to 2 classes.\n",
      "\n",
      "Test Set\n",
      "Found 2276 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"Training Set\")\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=['non', 'real'],\n",
    "    batch_size=BATCH_SIZE)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Test Set\")\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=['non', 'real'],\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 18s 0us/step\n",
      "87924736/87910968 [==============================] - 18s 0us/step\n",
      "Modified Inception V3 model ready\n"
     ]
    }
   ],
   "source": [
    "# Initialize Inception Model\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add top layers\n",
    "x = inception_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu', name='fc1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Combine base model with top layers\n",
    "model = Model(inception_model.input, predictions)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print(\"Modified Inception V3 model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/pxqlgx6n02b943rwp60qx4080000gn/T/ipykernel_10340/638570618.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  training = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "245/250 [============================>.] - ETA: 14s - loss: 0.4633 - accuracy: 0.7860WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1250 batches). You may need to use the repeat() function when building your dataset.\n",
      "250/250 [==============================] - 884s 4s/step - loss: 0.4633 - accuracy: 0.7860 - val_loss: 0.4230 - val_accuracy: 0.8065\n"
     ]
    }
   ],
   "source": [
    "training = model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    steps_per_epoch= TRAIN_SIZE // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps= TEST_SIZE // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(16,6))\n",
    "\n",
    "# loss history\n",
    "ax0.plot(training.history['loss'])\n",
    "ax0.plot(training.history['val_loss'])\n",
    "ax0.set_title('Model Loss')\n",
    "ax0.set_ylabel('Loss')\n",
    "ax0.set_xlabel('Epoch')\n",
    "ax0.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "#accuracy history\n",
    "ax1.plot(training.history['accuracy'])\n",
    "ax1.plot(training.history['val_accuracy'])\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
